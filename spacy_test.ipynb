{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['source internet protocol mean', 'destination internet protocol mean','protocol mean','source port mean','destination port mean','internet protocol length mean','inter arrival time mean',\n",
    "        'source internet protocol standard deviation', 'destination internet protocol standard deviation','protocol standard deviation','source port standard deviation','destination port standard deviation','internet protocol length standard deviation','inter arrival time standard deviation',\n",
    "        'source internet protocol skewness', 'destination internet protocol skewness','protocol skewness','source port skewness','destination port skewness','internet protocol length skewness','inter arrival time skewness',\n",
    "        'source internet protocol kurtosis', 'destination internet protocol kurtosis','protocol kurtosis','source port kurtosis','destination port kurtosis','internet protocol length kurtosis','inter arrival time kurtosis',\n",
    "        'source internet protocol entropy', 'destination internet protocol entropy','protocol entropy','source port entropy','destination port entropy','internet protocol length entropy','inter arrival time entropy',\n",
    "        'source internet protocol distinct', 'destination internet protocol distinct','protocol distinct','source port distinct','destination port distinct','internet protocol length distinct','inter arrival time distinct',\n",
    "        'source internet protocol q1', 'destination internet protocol q1','protocol q1','source port q1','destination port q1','internet protocol length q1','inter arrival time q1',\n",
    "        'source internet protocol q2', 'destination internet protocol q2','protocol q2','source port q2','destination port q2','internet protocol length q2','inter arrival time q2',\n",
    "        'source internet protocol q3', 'destination internet protocol q3','protocol q3','source port q3','destination port q3','internet protocol length q3','inter arrival time q3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = np.load('../SHAP/Network/traces/ml_data_example/data0.npy')\n",
    "vocab_df = pd.DataFrame(vocab, columns=cols)\n",
    "\n",
    "vocab_df = vocab_df.round(8)\n",
    "vocab_df = vocab_df.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" vocab_df['source internet protocol mean'][0] = 'source internet protocol mean : ' + str(vocab_df['source internet protocol mean'][0])\\nvocab_df['source internet protocol mean'][0] \""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" vocab_df['source internet protocol mean'][0] = 'source internet protocol mean : ' + str(vocab_df['source internet protocol mean'][0])\n",
    "vocab_df['source internet protocol mean'][0] \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cols:\n",
    "    vocab_df[col] = col + ' : ' + vocab_df[col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source internet protocol mean</th>\n",
       "      <th>destination internet protocol mean</th>\n",
       "      <th>protocol mean</th>\n",
       "      <th>source port mean</th>\n",
       "      <th>destination port mean</th>\n",
       "      <th>internet protocol length mean</th>\n",
       "      <th>inter arrival time mean</th>\n",
       "      <th>source internet protocol standard deviation</th>\n",
       "      <th>destination internet protocol standard deviation</th>\n",
       "      <th>protocol standard deviation</th>\n",
       "      <th>...</th>\n",
       "      <th>destination port q2</th>\n",
       "      <th>internet protocol length q2</th>\n",
       "      <th>inter arrival time q2</th>\n",
       "      <th>source internet protocol q3</th>\n",
       "      <th>destination internet protocol q3</th>\n",
       "      <th>protocol q3</th>\n",
       "      <th>source port q3</th>\n",
       "      <th>destination port q3</th>\n",
       "      <th>internet protocol length q3</th>\n",
       "      <th>inter arrival time q3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>source internet protocol mean : 0.86660023</td>\n",
       "      <td>destination internet protocol mean : 0.74068214</td>\n",
       "      <td>protocol mean : 0.00992919</td>\n",
       "      <td>source port mean : 0.60208216</td>\n",
       "      <td>destination port mean : 0.33323211</td>\n",
       "      <td>internet protocol length mean : 0.18181818</td>\n",
       "      <td>inter arrival time mean : 0.00222783</td>\n",
       "      <td>source internet protocol standard deviation : 0.0</td>\n",
       "      <td>destination internet protocol standard deviati...</td>\n",
       "      <td>protocol standard deviation : 0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>destination port q2 : 0.00266667</td>\n",
       "      <td>internet protocol length q2 : 0.0</td>\n",
       "      <td>inter arrival time q2 : 0.55797101</td>\n",
       "      <td>source internet protocol q3 : 0.0</td>\n",
       "      <td>destination internet protocol q3 : 0.0</td>\n",
       "      <td>protocol q3 : 0.0</td>\n",
       "      <td>source port q3 : 0.19238715</td>\n",
       "      <td>destination port q3 : 0.00651859</td>\n",
       "      <td>internet protocol length q3 : 0.0</td>\n",
       "      <td>inter arrival time q3 : 0.5538544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>source internet protocol mean : 0.86660023</td>\n",
       "      <td>destination internet protocol mean : 0.74068214</td>\n",
       "      <td>protocol mean : 0.00992919</td>\n",
       "      <td>source port mean : 0.75989928</td>\n",
       "      <td>destination port mean : 0.32919155</td>\n",
       "      <td>internet protocol length mean : 0.18181818</td>\n",
       "      <td>inter arrival time mean : 0.00129753</td>\n",
       "      <td>source internet protocol standard deviation : 0.0</td>\n",
       "      <td>destination internet protocol standard deviati...</td>\n",
       "      <td>protocol standard deviation : 0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>destination port q2 : 0.00266667</td>\n",
       "      <td>internet protocol length q2 : 0.0</td>\n",
       "      <td>inter arrival time q2 : 0.10144928</td>\n",
       "      <td>source internet protocol q3 : 0.0</td>\n",
       "      <td>destination internet protocol q3 : 0.0</td>\n",
       "      <td>protocol q3 : 0.0</td>\n",
       "      <td>source port q3 : 0.14648038</td>\n",
       "      <td>destination port q3 : 0.02266343</td>\n",
       "      <td>internet protocol length q3 : 0.0</td>\n",
       "      <td>inter arrival time q3 : 0.54459786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>source internet protocol mean : 0.86660023</td>\n",
       "      <td>destination internet protocol mean : 0.74068214</td>\n",
       "      <td>protocol mean : 0.00992919</td>\n",
       "      <td>source port mean : 0.55541402</td>\n",
       "      <td>destination port mean : 0.33415343</td>\n",
       "      <td>internet protocol length mean : 0.18181818</td>\n",
       "      <td>inter arrival time mean : 0.00771866</td>\n",
       "      <td>source internet protocol standard deviation : 0.0</td>\n",
       "      <td>destination internet protocol standard deviati...</td>\n",
       "      <td>protocol standard deviation : 0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>destination port q2 : 0.00266667</td>\n",
       "      <td>internet protocol length q2 : 0.0</td>\n",
       "      <td>inter arrival time q2 : 0.35024155</td>\n",
       "      <td>source internet protocol q3 : 0.0</td>\n",
       "      <td>destination internet protocol q3 : 0.0</td>\n",
       "      <td>protocol q3 : 0.0</td>\n",
       "      <td>source port q3 : 0.19250706</td>\n",
       "      <td>destination port q3 : 0.0038545</td>\n",
       "      <td>internet protocol length q3 : 0.0</td>\n",
       "      <td>inter arrival time q3 : 0.43391584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>source internet protocol mean : 0.8670171</td>\n",
       "      <td>destination internet protocol mean : 0.74014967</td>\n",
       "      <td>protocol mean : 0.00989816</td>\n",
       "      <td>source port mean : 0.76076028</td>\n",
       "      <td>destination port mean : 0.33349641</td>\n",
       "      <td>internet protocol length mean : 0.18125</td>\n",
       "      <td>inter arrival time mean : 0.00142466</td>\n",
       "      <td>source internet protocol standard deviation : ...</td>\n",
       "      <td>destination internet protocol standard deviati...</td>\n",
       "      <td>protocol standard deviation : 0.00111242</td>\n",
       "      <td>...</td>\n",
       "      <td>destination port q2 : 0.00533333</td>\n",
       "      <td>internet protocol length q2 : 0.33333333</td>\n",
       "      <td>inter arrival time q2 : 0.5410628</td>\n",
       "      <td>source internet protocol q3 : 0.00327265</td>\n",
       "      <td>destination internet protocol q3 : 0.00327265</td>\n",
       "      <td>protocol q3 : 0.00327265</td>\n",
       "      <td>source port q3 : 0.20573455</td>\n",
       "      <td>destination port q3 : 0.00914293</td>\n",
       "      <td>internet protocol length q3 : 0.00327265</td>\n",
       "      <td>inter arrival time q3 : 0.46260208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>source internet protocol mean : 0.86291511</td>\n",
       "      <td>destination internet protocol mean : 0.73971806</td>\n",
       "      <td>protocol mean : 0.01511285</td>\n",
       "      <td>source port mean : 0.93687304</td>\n",
       "      <td>destination port mean : 0.33130656</td>\n",
       "      <td>internet protocol length mean : 0.18034759</td>\n",
       "      <td>inter arrival time mean : 0.01147068</td>\n",
       "      <td>source internet protocol standard deviation : ...</td>\n",
       "      <td>destination internet protocol standard deviati...</td>\n",
       "      <td>protocol standard deviation : 0.13572855</td>\n",
       "      <td>...</td>\n",
       "      <td>destination port q2 : 0.00533333</td>\n",
       "      <td>internet protocol length q2 : 0.33333333</td>\n",
       "      <td>inter arrival time q2 : 0.18357488</td>\n",
       "      <td>source internet protocol q3 : 0.01237212</td>\n",
       "      <td>destination internet protocol q3 : 0.01237212</td>\n",
       "      <td>protocol q3 : 0.01237212</td>\n",
       "      <td>source port q3 : 0.12679338</td>\n",
       "      <td>destination port q3 : 0.01237212</td>\n",
       "      <td>internet protocol length q3 : 0.01097312</td>\n",
       "      <td>inter arrival time q3 : 0.41760252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                source internet protocol mean  \\\n",
       "0  source internet protocol mean : 0.86660023   \n",
       "1  source internet protocol mean : 0.86660023   \n",
       "2  source internet protocol mean : 0.86660023   \n",
       "3   source internet protocol mean : 0.8670171   \n",
       "4  source internet protocol mean : 0.86291511   \n",
       "\n",
       "                destination internet protocol mean  \\\n",
       "0  destination internet protocol mean : 0.74068214   \n",
       "1  destination internet protocol mean : 0.74068214   \n",
       "2  destination internet protocol mean : 0.74068214   \n",
       "3  destination internet protocol mean : 0.74014967   \n",
       "4  destination internet protocol mean : 0.73971806   \n",
       "\n",
       "                protocol mean               source port mean  \\\n",
       "0  protocol mean : 0.00992919  source port mean : 0.60208216   \n",
       "1  protocol mean : 0.00992919  source port mean : 0.75989928   \n",
       "2  protocol mean : 0.00992919  source port mean : 0.55541402   \n",
       "3  protocol mean : 0.00989816  source port mean : 0.76076028   \n",
       "4  protocol mean : 0.01511285  source port mean : 0.93687304   \n",
       "\n",
       "                destination port mean  \\\n",
       "0  destination port mean : 0.33323211   \n",
       "1  destination port mean : 0.32919155   \n",
       "2  destination port mean : 0.33415343   \n",
       "3  destination port mean : 0.33349641   \n",
       "4  destination port mean : 0.33130656   \n",
       "\n",
       "                internet protocol length mean  \\\n",
       "0  internet protocol length mean : 0.18181818   \n",
       "1  internet protocol length mean : 0.18181818   \n",
       "2  internet protocol length mean : 0.18181818   \n",
       "3     internet protocol length mean : 0.18125   \n",
       "4  internet protocol length mean : 0.18034759   \n",
       "\n",
       "                inter arrival time mean  \\\n",
       "0  inter arrival time mean : 0.00222783   \n",
       "1  inter arrival time mean : 0.00129753   \n",
       "2  inter arrival time mean : 0.00771866   \n",
       "3  inter arrival time mean : 0.00142466   \n",
       "4  inter arrival time mean : 0.01147068   \n",
       "\n",
       "         source internet protocol standard deviation  \\\n",
       "0  source internet protocol standard deviation : 0.0   \n",
       "1  source internet protocol standard deviation : 0.0   \n",
       "2  source internet protocol standard deviation : 0.0   \n",
       "3  source internet protocol standard deviation : ...   \n",
       "4  source internet protocol standard deviation : ...   \n",
       "\n",
       "    destination internet protocol standard deviation  \\\n",
       "0  destination internet protocol standard deviati...   \n",
       "1  destination internet protocol standard deviati...   \n",
       "2  destination internet protocol standard deviati...   \n",
       "3  destination internet protocol standard deviati...   \n",
       "4  destination internet protocol standard deviati...   \n",
       "\n",
       "                protocol standard deviation  ...  \\\n",
       "0         protocol standard deviation : 0.0  ...   \n",
       "1         protocol standard deviation : 0.0  ...   \n",
       "2         protocol standard deviation : 0.0  ...   \n",
       "3  protocol standard deviation : 0.00111242  ...   \n",
       "4  protocol standard deviation : 0.13572855  ...   \n",
       "\n",
       "                destination port q2               internet protocol length q2  \\\n",
       "0  destination port q2 : 0.00266667         internet protocol length q2 : 0.0   \n",
       "1  destination port q2 : 0.00266667         internet protocol length q2 : 0.0   \n",
       "2  destination port q2 : 0.00266667         internet protocol length q2 : 0.0   \n",
       "3  destination port q2 : 0.00533333  internet protocol length q2 : 0.33333333   \n",
       "4  destination port q2 : 0.00533333  internet protocol length q2 : 0.33333333   \n",
       "\n",
       "                inter arrival time q2  \\\n",
       "0  inter arrival time q2 : 0.55797101   \n",
       "1  inter arrival time q2 : 0.10144928   \n",
       "2  inter arrival time q2 : 0.35024155   \n",
       "3   inter arrival time q2 : 0.5410628   \n",
       "4  inter arrival time q2 : 0.18357488   \n",
       "\n",
       "                source internet protocol q3  \\\n",
       "0         source internet protocol q3 : 0.0   \n",
       "1         source internet protocol q3 : 0.0   \n",
       "2         source internet protocol q3 : 0.0   \n",
       "3  source internet protocol q3 : 0.00327265   \n",
       "4  source internet protocol q3 : 0.01237212   \n",
       "\n",
       "                destination internet protocol q3               protocol q3  \\\n",
       "0         destination internet protocol q3 : 0.0         protocol q3 : 0.0   \n",
       "1         destination internet protocol q3 : 0.0         protocol q3 : 0.0   \n",
       "2         destination internet protocol q3 : 0.0         protocol q3 : 0.0   \n",
       "3  destination internet protocol q3 : 0.00327265  protocol q3 : 0.00327265   \n",
       "4  destination internet protocol q3 : 0.01237212  protocol q3 : 0.01237212   \n",
       "\n",
       "                source port q3               destination port q3  \\\n",
       "0  source port q3 : 0.19238715  destination port q3 : 0.00651859   \n",
       "1  source port q3 : 0.14648038  destination port q3 : 0.02266343   \n",
       "2  source port q3 : 0.19250706   destination port q3 : 0.0038545   \n",
       "3  source port q3 : 0.20573455  destination port q3 : 0.00914293   \n",
       "4  source port q3 : 0.12679338  destination port q3 : 0.01237212   \n",
       "\n",
       "                internet protocol length q3  \\\n",
       "0         internet protocol length q3 : 0.0   \n",
       "1         internet protocol length q3 : 0.0   \n",
       "2         internet protocol length q3 : 0.0   \n",
       "3  internet protocol length q3 : 0.00327265   \n",
       "4  internet protocol length q3 : 0.01097312   \n",
       "\n",
       "                inter arrival time q3  \n",
       "0   inter arrival time q3 : 0.5538544  \n",
       "1  inter arrival time q3 : 0.54459786  \n",
       "2  inter arrival time q3 : 0.43391584  \n",
       "3  inter arrival time q3 : 0.46260208  \n",
       "4  inter arrival time q3 : 0.41760252  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'source internet protocol mean : 0.86660023,destination internet protocol mean : 0.74068214,protocol mean : 0.00992919,source port mean : 0.60208216,destination port mean : 0.33323211,internet protocol length mean : 0.18181818,inter arrival time mean : 0.00222783'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq1 = vocab_df['source internet protocol mean'][0] + ',' + vocab_df['destination internet protocol mean'][0] + ',' + vocab_df['protocol mean'][0] + ',' + vocab_df['source port mean'][0] + ',' + vocab_df['destination port mean'][0] + ',' + vocab_df['internet protocol length mean'][0] + ',' + vocab_df['inter arrival time mean'][0]\n",
    "seq1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>source internet protocol mean : 0.86660023 , d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>source internet protocol mean : 0.86660023 , d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>source internet protocol mean : 0.86660023 , d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>source internet protocol mean : 0.8670171 , de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>source internet protocol mean : 0.86291511 , d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  source internet protocol mean : 0.86660023 , d...\n",
       "1  source internet protocol mean : 0.86660023 , d...\n",
       "2  source internet protocol mean : 0.86660023 , d...\n",
       "3  source internet protocol mean : 0.8670171 , de...\n",
       "4  source internet protocol mean : 0.86291511 , d..."
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_list = []\n",
    "for seq in vocab_df.index.values:\n",
    "    seq_mean = vocab_df['source internet protocol mean'][seq] + ' , ' + vocab_df['destination internet protocol mean'][seq] + ' , ' + vocab_df['protocol mean'][seq] + ' , ' + vocab_df['source port mean'][seq] + ' , ' + vocab_df['destination port mean'][seq] + ' , ' + vocab_df['internet protocol length mean'][seq] + ' , ' + vocab_df['inter arrival time mean'][seq] \n",
    "    seq_std = vocab_df['source internet protocol standard deviation'][seq] + ' , ' + vocab_df['destination internet protocol standard deviation'][seq] + ' , ' + vocab_df['protocol standard deviation'][seq] + ' , ' + vocab_df['source port standard deviation'][seq] + ' , ' + vocab_df['destination port standard deviation'][seq] + ' , ' + vocab_df['internet protocol length standard deviation'][seq] + ' , ' + vocab_df['inter arrival time standard deviation'][seq]\n",
    "    seq_skew = vocab_df['source internet protocol skewness'][seq] + ' , ' + vocab_df['destination internet protocol skewness'][seq] + ' , ' + vocab_df['protocol skewness'][seq] + ' , ' + vocab_df['source port skewness'][seq] + ' , ' + vocab_df['destination port skewness'][seq] + ' , ' + vocab_df['internet protocol length skewness'][seq] + ' , ' + vocab_df['inter arrival time skewness'][seq]\n",
    "    seq_kurt = vocab_df['source internet protocol kurtosis'][seq] + ' , ' + vocab_df['destination internet protocol kurtosis'][seq] + ' , ' + vocab_df['protocol kurtosis'][seq] + ' , ' + vocab_df['source port kurtosis'][seq] + ' , ' + vocab_df['destination port kurtosis'][seq] + ' , ' + vocab_df['internet protocol length kurtosis'][seq] + ' , ' + vocab_df['inter arrival time kurtosis'][seq]\n",
    "    seq_entropy = vocab_df['source internet protocol entropy'][seq] + ' , ' + vocab_df['destination internet protocol entropy'][seq] + ' , ' + vocab_df['protocol entropy'][seq] + ' , ' + vocab_df['source port entropy'][seq] + ' , ' + vocab_df['destination port entropy'][seq] + ' , ' + vocab_df['internet protocol length entropy'][seq] + ' , ' + vocab_df['inter arrival time entropy'][seq]\n",
    "    seq_distinct = vocab_df['source internet protocol distinct'][seq] + ' , ' + vocab_df['destination internet protocol distinct'][seq] + ' , ' + vocab_df['protocol distinct'][seq] + ' , ' + vocab_df['source port distinct'][seq] + ' , ' + vocab_df['destination port distinct'][seq] + ' , ' + vocab_df['internet protocol length distinct'][seq] + ' , ' + vocab_df['inter arrival time distinct'][seq]\n",
    "    seq_q1 = vocab_df['source internet protocol q1'][seq] + ' , ' + vocab_df['destination internet protocol q1'][seq] + ' , ' + vocab_df['protocol q1'][seq] + ' , ' + vocab_df['source port q1'][seq] + ' , ' + vocab_df['destination port q1'][seq] + ' , ' + vocab_df['internet protocol length q1'][seq] + ' , ' + vocab_df['inter arrival time q1'][seq]\n",
    "    seq_q2 = vocab_df['source internet protocol q2'][seq] + ' , ' + vocab_df['destination internet protocol q2'][seq] + ' , ' + vocab_df['protocol q2'][seq] + ' , ' + vocab_df['source port q2'][seq] + ' , ' + vocab_df['destination port q2'][seq] + ' , ' + vocab_df['internet protocol length q2'][seq] + ' , ' + vocab_df['inter arrival time q2'][seq]\n",
    "    seq_q3 = vocab_df['source internet protocol q3'][seq] + ' , ' + vocab_df['destination internet protocol q3'][seq] + ' , ' + vocab_df['protocol q3'][seq] + ' , ' + vocab_df['source port q3'][seq] + ' , ' + vocab_df['destination port q3'][seq] + ' , ' + vocab_df['internet protocol length q3'][seq] + ' , ' + vocab_df['inter arrival time q3'][seq]\n",
    "    seq = seq_mean + ' , ' + seq_std + ' , ' + seq_skew + ' , ' + seq_kurt + ' , ' + seq_entropy + ' , ' + seq_distinct + ' , ' + seq_q1 + ' , ' + seq_q2 + ' , ' + seq_q3\n",
    "    seq_list.append(seq)\n",
    "\n",
    "seq_df = pd.DataFrame(seq_list)\n",
    "seq_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source\t0\tsource\tFalse\tFalse\tNN\t[6]\n",
      "internet\t7\tinternet\tFalse\tFalse\tNN\t[6]\n",
      "protocol\t16\tprotocol\tFalse\tFalse\tNN\t[6]\n",
      "mean\t25\tmean\tFalse\tFalse\tVBP\t[6]\n",
      ":\t30\t:\tTrue\tFalse\t:\t[6]\n",
      "0.86660023\t32\t0.86660023\tFalse\tFalse\tCD\t[6]\n",
      ",\t43\t,\tTrue\tFalse\t,\t[6]\n",
      "destination\t45\tdestination\tFalse\tFalse\tNN\t[6]\n",
      "internet\t57\tinternet\tFalse\tFalse\tNN\t[6]\n",
      "protocol\t66\tprotocol\tFalse\tFalse\tNN\t[6]\n",
      "mean\t75\tmean\tFalse\tFalse\tVBP\t[6]\n",
      ":\t80\t:\tTrue\tFalse\t:\t[6]\n",
      "0.74068214\t82\t0.74068214\tFalse\tFalse\tCD\t[6]\n",
      ",\t93\t,\tTrue\tFalse\t,\t[6]\n",
      "protocol\t95\tprotocol\tFalse\tFalse\tNN\t[6]\n",
      "mean\t104\tmean\tFalse\tFalse\tVB\t[6]\n",
      ":\t109\t:\tTrue\tFalse\t:\t[6]\n",
      "0.00992919\t111\t0.00992919\tFalse\tFalse\tCD\t[6]\n",
      ",\t122\t,\tTrue\tFalse\t,\t[6]\n",
      "source\t124\tsource\tFalse\tFalse\tNN\t[6]\n",
      "port\t131\tport\tFalse\tFalse\tNN\t[6]\n",
      "mean\t136\tmean\tFalse\tFalse\tNN\t[6]\n",
      ":\t141\t:\tTrue\tFalse\t:\t[6]\n",
      "0.60208216\t143\t0.60208216\tFalse\tFalse\tCD\t[6]\n",
      ",\t154\t,\tTrue\tFalse\t,\t[6]\n",
      "destination\t156\tdestination\tFalse\tFalse\tNN\t[6]\n",
      "port\t168\tport\tFalse\tFalse\tNN\t[6]\n",
      "mean\t173\tmean\tFalse\tFalse\tNN\t[6]\n",
      ":\t178\t:\tTrue\tFalse\t:\t[6]\n",
      "0.33323211\t180\t0.33323211\tFalse\tFalse\tCD\t[6]\n",
      ",\t191\t,\tTrue\tFalse\t,\t[6]\n",
      "internet\t193\tinternet\tFalse\tFalse\tNN\t[6]\n",
      "protocol\t202\tprotocol\tFalse\tFalse\tNN\t[6]\n",
      "length\t211\tlength\tFalse\tFalse\tNN\t[6]\n",
      "mean\t218\tmean\tFalse\tFalse\tNN\t[6]\n",
      ":\t223\t:\tTrue\tFalse\t:\t[6]\n",
      "0.18181818\t225\t0.18181818\tFalse\tFalse\tCD\t[6]\n",
      ",\t236\t,\tTrue\tFalse\t,\t[6]\n",
      "inter\t238\tinter\tFalse\tFalse\tNN\t[6]\n",
      "arrival\t244\tarrival\tFalse\tFalse\tNN\t[6]\n",
      "time\t252\ttime\tFalse\tFalse\tNN\t[6]\n",
      "mean\t257\tmean\tFalse\tFalse\tVBP\t[6]\n",
      ":\t262\t:\tTrue\tFalse\t:\t[6]\n",
      "0.00222783\t264\t0.00222783\tFalse\tFalse\tCD\t[6]\n",
      ",\t275\t,\tTrue\tFalse\t,\t[6]\n",
      "source\t277\tsource\tFalse\tFalse\tNN\t[6]\n",
      "internet\t284\tinternet\tFalse\tFalse\tNN\t[6]\n",
      "protocol\t293\tprotocol\tFalse\tFalse\tNN\t[6]\n",
      "standard\t302\tstandard\tFalse\tFalse\tJJ\t[6]\n",
      "deviation\t311\tdeviation\tFalse\tFalse\tNN\t[6]\n",
      ":\t321\t:\tTrue\tFalse\t:\t[6]\n",
      "0.0\t323\t0.0\tFalse\tFalse\tCD\t[6]\n",
      ",\t327\t,\tTrue\tFalse\t,\t[6]\n",
      "destination\t329\tdestination\tFalse\tFalse\tNN\t[6]\n",
      "internet\t341\tinternet\tFalse\tFalse\tNN\t[6]\n",
      "protocol\t350\tprotocol\tFalse\tFalse\tNN\t[6]\n",
      "standard\t359\tstandard\tFalse\tFalse\tJJ\t[6]\n",
      "deviation\t368\tdeviation\tFalse\tFalse\tNN\t[6]\n",
      ":\t378\t:\tTrue\tFalse\t:\t[6]\n",
      "0.0\t380\t0.0\tFalse\tFalse\tCD\t[6]\n",
      ",\t384\t,\tTrue\tFalse\t,\t[6]\n",
      "protocol\t386\tprotocol\tFalse\tFalse\tNN\t[6]\n",
      "standard\t395\tstandard\tFalse\tFalse\tJJ\t[6]\n",
      "deviation\t404\tdeviation\tFalse\tFalse\tNN\t[6]\n",
      ":\t414\t:\tTrue\tFalse\t:\t[6]\n",
      "0.0\t416\t0.0\tFalse\tFalse\tCD\t[6]\n",
      ",\t420\t,\tTrue\tFalse\t,\t[6]\n",
      "source\t422\tsource\tFalse\tFalse\tNN\t[6]\n",
      "port\t429\tport\tFalse\tFalse\tNN\t[6]\n",
      "standard\t434\tstandard\tFalse\tFalse\tJJ\t[6]\n",
      "deviation\t443\tdeviation\tFalse\tFalse\tNN\t[6]\n",
      ":\t453\t:\tTrue\tFalse\t:\t[6]\n",
      "0.21686882\t455\t0.21686882\tFalse\tFalse\tCD\t[6]\n",
      ",\t466\t,\tTrue\tFalse\t,\t[6]\n",
      "destination\t468\tdestination\tFalse\tFalse\tNN\t[6]\n",
      "port\t480\tport\tFalse\tFalse\tNN\t[6]\n",
      "standard\t485\tstandard\tFalse\tFalse\tJJ\t[6]\n",
      "deviation\t494\tdeviation\tFalse\tFalse\tNN\t[6]\n",
      ":\t504\t:\tTrue\tFalse\t:\t[6]\n",
      "0.036159\t506\t0.036159\tFalse\tFalse\tCD\t[6]\n",
      ",\t515\t,\tTrue\tFalse\t,\t[6]\n",
      "internet\t517\tinternet\tFalse\tFalse\tNN\t[6]\n",
      "protocol\t526\tprotocol\tFalse\tFalse\tNN\t[6]\n",
      "length\t535\tlength\tFalse\tFalse\tNN\t[6]\n",
      "standard\t542\tstandard\tFalse\tFalse\tJJ\t[6]\n",
      "deviation\t551\tdeviation\tFalse\tFalse\tNN\t[6]\n",
      ":\t561\t:\tTrue\tFalse\t:\t[6]\n",
      "0.0\t563\t0.0\tFalse\tFalse\tCD\t[6]\n",
      ",\t567\t,\tTrue\tFalse\t,\t[6]\n",
      "inter\t569\tinter\tFalse\tFalse\tNN\t[6]\n",
      "arrival\t575\tarrival\tFalse\tFalse\tNN\t[6]\n",
      "time\t583\ttime\tFalse\tFalse\tNN\t[6]\n",
      "standard\t588\tstandard\tFalse\tFalse\tJJ\t[6]\n",
      "deviation\t597\tdeviation\tFalse\tFalse\tNN\t[6]\n",
      ":\t607\t:\tTrue\tFalse\t:\t[6]\n",
      "0.00434957\t609\t0.00434957\tFalse\tFalse\tCD\t[6]\n",
      ",\t620\t,\tTrue\tFalse\t,\t[6]\n",
      "source\t622\tsource\tFalse\tFalse\tNN\t[6]\n",
      "internet\t629\tinternet\tFalse\tFalse\tNN\t[6]\n",
      "protocol\t638\tprotocol\tFalse\tFalse\tNN\t[6]\n",
      "skewness\t647\tskewness\tFalse\tFalse\tNN\t[6]\n",
      ":\t656\t:\tTrue\tFalse\t:\t[6]\n",
      "0.4937372\t658\t0.4937372\tFalse\tFalse\tCD\t[6]\n",
      ",\t668\t,\tTrue\tFalse\t,\t[6]\n",
      "destination\t670\tdestination\tFalse\tFalse\tNN\t[6]\n",
      "internet\t682\tinternet\tFalse\tFalse\tNN\t[6]\n",
      "protocol\t691\tprotocol\tFalse\tFalse\tNN\t[6]\n",
      "skewness\t700\tskewness\tFalse\tFalse\tNN\t[6]\n",
      ":\t709\t:\tTrue\tFalse\t:\t[6]\n",
      "0.53802464\t711\t0.53802464\tFalse\tFalse\tCD\t[6]\n",
      ",\t722\t,\tTrue\tFalse\t,\t[6]\n",
      "protocol\t724\tprotocol\tFalse\tFalse\tNN\t[6]\n",
      "skewness\t733\tskewness\tFalse\tFalse\tNN\t[6]\n",
      ":\t742\t:\tTrue\tFalse\t:\t[6]\n",
      "0.18439253\t744\t0.18439253\tFalse\tFalse\tCD\t[6]\n",
      ",\t755\t,\tTrue\tFalse\t,\t[6]\n",
      "source\t757\tsource\tFalse\tFalse\tNN\t[6]\n",
      "port\t764\tport\tFalse\tFalse\tNN\t[6]\n",
      "skewness\t769\tskewness\tFalse\tFalse\tNN\t[6]\n",
      ":\t778\t:\tTrue\tFalse\t:\t[6]\n",
      "0.27852452\t780\t0.27852452\tFalse\tFalse\tCD\t[6]\n",
      ",\t791\t,\tTrue\tFalse\t,\t[6]\n",
      "destination\t793\tdestination\tFalse\tFalse\tNN\t[6]\n",
      "port\t805\tport\tFalse\tFalse\tNN\t[6]\n",
      "skewness\t810\tskewness\tFalse\tFalse\tNN\t[6]\n",
      ":\t819\t:\tTrue\tFalse\t:\t[6]\n",
      "0.4357907\t821\t0.4357907\tFalse\tFalse\tCD\t[6]\n",
      ",\t831\t,\tTrue\tFalse\t,\t[6]\n",
      "internet\t833\tinternet\tFalse\tFalse\tNN\t[6]\n",
      "protocol\t842\tprotocol\tFalse\tFalse\tNN\t[6]\n",
      "length\t851\tlength\tFalse\tFalse\tNN\t[6]\n",
      "skewness\t858\tskewness\tFalse\tFalse\tNN\t[6]\n",
      ":\t867\t:\tTrue\tFalse\t:\t[6]\n",
      "0.64450623\t869\t0.64450623\tFalse\tFalse\tCD\t[6]\n",
      ",\t880\t,\tTrue\tFalse\t,\t[6]\n",
      "inter\t882\tinter\tFalse\tFalse\tNN\t[6]\n",
      "arrival\t888\tarrival\tFalse\tFalse\tNN\t[6]\n",
      "time\t896\ttime\tFalse\tFalse\tNN\t[6]\n",
      "skewness\t901\tskewness\tFalse\tFalse\tNN\t[6]\n",
      ":\t910\t:\tTrue\tFalse\t:\t[6]\n",
      "0.15896699\t912\t0.15896699\tFalse\tFalse\tCD\t[6]\n",
      ",\t923\t,\tTrue\tFalse\t,\t[6]\n",
      "source\t925\tsource\tFalse\tFalse\tNN\t[6]\n",
      "internet\t932\tinternet\tFalse\tFalse\tNN\t[6]\n",
      "protocol\t941\tprotocol\tFalse\tFalse\tNN\t[6]\n",
      "kurtosis\t950\tkurtosis\tFalse\tFalse\tNN\t[6]\n",
      ":\t959\t:\tTrue\tFalse\t:\t[6]\n",
      "0.0\t961\t0.0\tFalse\tFalse\tCD\t[6]\n",
      ",\t965\t,\tTrue\tFalse\t,\t[6]\n",
      "destination\t967\tdestination\tFalse\tFalse\tNN\t[6]\n",
      "internet\t979\tinternet\tFalse\tFalse\tNN\t[6]\n",
      "protocol\t988\tprotocol\tFalse\tFalse\tNN\t[6]\n",
      "kurtosis\t997\tkurtosis\tFalse\tFalse\tNN\t[6]\n",
      ":\t1006\t:\tTrue\tFalse\t:\t[6]\n",
      "0.0\t1008\t0.0\tFalse\tFalse\tCD\t[6]\n",
      ",\t1012\t,\tTrue\tFalse\t,\t[6]\n",
      "protocol\t1014\tprotocol\tFalse\tFalse\tNN\t[6]\n",
      "kurtosis\t1023\tkurtosis\tFalse\tFalse\tNN\t[6]\n",
      ":\t1032\t:\tTrue\tFalse\t:\t[6]\n",
      "0.0\t1034\t0.0\tFalse\tFalse\tCD\t[6]\n",
      ",\t1038\t,\tTrue\tFalse\t,\t[6]\n",
      "source\t1040\tsource\tFalse\tFalse\tNN\t[6]\n",
      "port\t1047\tport\tFalse\tFalse\tNN\t[6]\n",
      "kurtosis\t1052\tkurtosis\tFalse\tFalse\tNN\t[6]\n",
      ":\t1061\t:\tTrue\tFalse\t:\t[6]\n",
      "0.05381951\t1063\t0.05381951\tFalse\tFalse\tCD\t[6]\n",
      ",\t1074\t,\tTrue\tFalse\t,\t[6]\n",
      "destination\t1076\tdestination\tFalse\tFalse\tNN\t[6]\n",
      "port\t1088\tport\tFalse\tFalse\tNN\t[6]\n",
      "kurtosis\t1093\tkurtosis\tFalse\tFalse\tNN\t[6]\n",
      ":\t1102\t:\tTrue\tFalse\t:\t[6]\n",
      "0.01881635\t1104\t0.01881635\tFalse\tFalse\tCD\t[6]\n",
      ",\t1115\t,\tTrue\tFalse\t,\t[6]\n",
      "internet\t1117\tinternet\tFalse\tFalse\tNN\t[6]\n",
      "protocol\t1126\tprotocol\tFalse\tFalse\tNN\t[6]\n",
      "length\t1135\tlength\tFalse\tFalse\tNN\t[6]\n",
      "kurtosis\t1142\tkurtosis\tFalse\tFalse\tNN\t[6]\n",
      ":\t1151\t:\tTrue\tFalse\t:\t[6]\n",
      "0.0\t1153\t0.0\tFalse\tFalse\tCD\t[6]\n",
      ",\t1157\t,\tTrue\tFalse\t,\t[6]\n",
      "inter\t1159\tinter\tFalse\tFalse\tNN\t[6]\n",
      "arrival\t1165\tarrival\tFalse\tFalse\tNN\t[6]\n",
      "time\t1173\ttime\tFalse\tFalse\tNN\t[6]\n",
      "kurtosis\t1178\tkurtosis\tFalse\tFalse\tNN\t[6]\n",
      ":\t1187\t:\tTrue\tFalse\t:\t[6]\n",
      "0.0262479\t1189\t0.0262479\tFalse\tFalse\tCD\t[6]\n",
      ",\t1199\t,\tTrue\tFalse\t,\t[6]\n",
      "source\t1201\tsource\tFalse\tFalse\tNN\t[6]\n",
      "internet\t1208\tinternet\tFalse\tFalse\tNN\t[6]\n",
      "protocol\t1217\tprotocol\tFalse\tFalse\tNN\t[6]\n",
      "entropy\t1226\tentropy\tFalse\tFalse\tNNP\t[6]\n",
      ":\t1234\t:\tTrue\tFalse\t:\t[6]\n",
      "0.86660023\t1236\t0.86660023\tFalse\tFalse\tCD\t[6]\n",
      ",\t1247\t,\tTrue\tFalse\t,\t[6]\n",
      "destination\t1249\tdestination\tFalse\tFalse\tNN\t[6]\n",
      "internet\t1261\tinternet\tFalse\tFalse\tNN\t[6]\n",
      "protocol\t1270\tprotocol\tFalse\tFalse\tNN\t[6]\n",
      "entropy\t1279\tentropy\tFalse\tFalse\tNNP\t[6]\n",
      ":\t1287\t:\tTrue\tFalse\t:\t[6]\n",
      "0.81486863\t1289\t0.81486863\tFalse\tFalse\tCD\t[6]\n",
      ",\t1300\t,\tTrue\tFalse\t,\t[6]\n",
      "protocol\t1302\tprotocol\tFalse\tFalse\tNN\t[6]\n",
      "entropy\t1311\tentropy\tFalse\tFalse\tNNP\t[6]\n",
      ":\t1319\t:\tTrue\tFalse\t:\t[6]\n",
      "0.0097555\t1321\t0.0097555\tFalse\tFalse\tCD\t[6]\n",
      ",\t1331\t,\tTrue\tFalse\t,\t[6]\n",
      "source\t1333\tsource\tFalse\tFalse\tNN\t[6]\n",
      "port\t1340\tport\tFalse\tFalse\tNN\t[6]\n",
      "entropy\t1345\tentropy\tFalse\tFalse\tNN\t[6]\n",
      ":\t1353\t:\tTrue\tFalse\t:\t[6]\n",
      "0.48869568\t1355\t0.48869568\tFalse\tFalse\tCD\t[6]\n",
      ",\t1366\t,\tTrue\tFalse\t,\t[6]\n",
      "destination\t1368\tdestination\tFalse\tFalse\tNN\t[6]\n",
      "port\t1380\tport\tFalse\tFalse\tNN\t[6]\n",
      "entropy\t1385\tentropy\tFalse\tFalse\tNN\t[6]\n",
      ":\t1393\t:\tTrue\tFalse\t:\t[6]\n",
      "0.31484203\t1395\t0.31484203\tFalse\tFalse\tCD\t[6]\n",
      ",\t1406\t,\tTrue\tFalse\t,\t[6]\n",
      "internet\t1408\tinternet\tFalse\tFalse\tNN\t[6]\n",
      "protocol\t1417\tprotocol\tFalse\tFalse\tNN\t[6]\n",
      "length\t1426\tlength\tFalse\tFalse\tNN\t[6]\n",
      "entropy\t1433\tentropy\tFalse\tFalse\tNNP\t[6]\n",
      ":\t1441\t:\tTrue\tFalse\t:\t[6]\n",
      "0.18181818\t1443\t0.18181818\tFalse\tFalse\tCD\t[6]\n",
      ",\t1454\t,\tTrue\tFalse\t,\t[6]\n",
      "inter\t1456\tinter\tFalse\tFalse\tNN\t[6]\n",
      "arrival\t1462\tarrival\tFalse\tFalse\tNN\t[6]\n",
      "time\t1470\ttime\tFalse\tFalse\tNN\t[6]\n",
      "entropy\t1475\tentropy\tFalse\tFalse\tNNP\t[6]\n",
      ":\t1483\t:\tTrue\tFalse\t:\t[6]\n",
      "1.915e-05\t1485\t1.915e-05\tFalse\tFalse\tCD\t[6]\n",
      ",\t1495\t,\tTrue\tFalse\t,\t[6]\n",
      "source\t1497\tsource\tFalse\tFalse\tNN\t[6]\n",
      "internet\t1504\tinternet\tFalse\tFalse\tNN\t[6]\n",
      "protocol\t1513\tprotocol\tFalse\tFalse\tNN\t[6]\n",
      "distinct\t1522\tdistinct\tFalse\tFalse\tNN\t[6]\n",
      ":\t1531\t:\tTrue\tFalse\t:\t[6]\n",
      "0.86660023\t1533\t0.86660023\tFalse\tFalse\tCD\t[6]\n",
      ",\t1544\t,\tTrue\tFalse\t,\t[6]\n",
      "destination\t1546\tdestination\tFalse\tFalse\tNN\t[6]\n",
      "internet\t1558\tinternet\tFalse\tFalse\tNN\t[6]\n",
      "protocol\t1567\tprotocol\tFalse\tFalse\tNN\t[6]\n",
      "distinct\t1576\tdistinct\tFalse\tFalse\tNN\t[6]\n",
      ":\t1585\t:\tTrue\tFalse\t:\t[6]\n",
      "0.74068214\t1587\t0.74068214\tFalse\tFalse\tCD\t[6]\n",
      ",\t1598\t,\tTrue\tFalse\t,\t[6]\n",
      "protocol\t1600\tprotocol\tFalse\tFalse\tNN\t[6]\n",
      "distinct\t1609\tdistinct\tFalse\tFalse\tNN\t[6]\n",
      ":\t1618\t:\tTrue\tFalse\t:\t[6]\n",
      "0.00972646\t1620\t0.00972646\tFalse\tFalse\tCD\t[6]\n",
      ",\t1631\t,\tTrue\tFalse\t,\t[6]\n",
      "source\t1633\tsource\tFalse\tFalse\tNN\t[6]\n",
      "port\t1640\tport\tFalse\tFalse\tNN\t[6]\n",
      "distinct\t1645\tdistinct\tFalse\tFalse\tNN\t[6]\n",
      ":\t1654\t:\tTrue\tFalse\t:\t[6]\n",
      "0.55976085\t1656\t0.55976085\tFalse\tFalse\tCD\t[6]\n",
      ",\t1667\t,\tTrue\tFalse\t,\t[6]\n",
      "destination\t1669\tdestination\tFalse\tFalse\tNN\t[6]\n",
      "port\t1681\tport\tFalse\tFalse\tNN\t[6]\n",
      "distinct\t1686\tdistinct\tFalse\tFalse\tNN\t[6]\n",
      ":\t1695\t:\tTrue\tFalse\t:\t[6]\n",
      "0.29315068\t1697\t0.29315068\tFalse\tFalse\tCD\t[6]\n",
      ",\t1708\t,\tTrue\tFalse\t,\t[6]\n",
      "internet\t1710\tinternet\tFalse\tFalse\tNN\t[6]\n",
      "protocol\t1719\tprotocol\tFalse\tFalse\tNN\t[6]\n",
      "length\t1728\tlength\tFalse\tFalse\tNN\t[6]\n",
      "distinct\t1735\tdistinct\tFalse\tFalse\tNN\t[6]\n",
      ":\t1744\t:\tTrue\tFalse\t:\t[6]\n",
      "0.18181818\t1746\t0.18181818\tFalse\tFalse\tCD\t[6]\n",
      ",\t1757\t,\tTrue\tFalse\t,\t[6]\n",
      "inter\t1759\tinter\tFalse\tFalse\tNN\t[6]\n",
      "arrival\t1765\tarrival\tFalse\tFalse\tNN\t[6]\n",
      "time\t1773\ttime\tFalse\tFalse\tNN\t[6]\n",
      "distinct\t1778\tdistinct\tFalse\tFalse\tJJ\t[6]\n",
      ":\t1787\t:\tTrue\tFalse\t:\t[6]\n",
      "3.225e-05\t1789\t3.225e-05\tFalse\tFalse\tCD\t[6]\n",
      ",\t1799\t,\tTrue\tFalse\t,\t[6]\n",
      "source\t1801\tsource\tFalse\tFalse\tNN\t[6]\n",
      "internet\t1808\tinternet\tFalse\tFalse\tNN\t[6]\n",
      "protocol\t1817\tprotocol\tFalse\tFalse\tNN\t[6]\n",
      "q1\t1826\tq1\tFalse\tFalse\tVBZ\t[6]\n",
      ":\t1829\t:\tTrue\tFalse\t:\t[6]\n",
      "0.86660021\t1831\t0.86660021\tFalse\tFalse\tCD\t[6]\n",
      ",\t1842\t,\tTrue\tFalse\t,\t[6]\n",
      "destination\t1844\tdestination\tFalse\tFalse\tNN\t[6]\n",
      "internet\t1856\tinternet\tFalse\tFalse\tNN\t[6]\n",
      "protocol\t1865\tprotocol\tFalse\tFalse\tNN\t[6]\n",
      "q1\t1874\tq1\tFalse\tFalse\tVBZ\t[6]\n",
      ":\t1877\t:\tTrue\tFalse\t:\t[6]\n",
      "0.67158376\t1879\t0.67158376\tFalse\tFalse\tCD\t[6]\n",
      ",\t1890\t,\tTrue\tFalse\t,\t[6]\n",
      "protocol\t1892\tprotocol\tFalse\tFalse\tNN\t[6]\n",
      "q1\t1901\tq1\tFalse\tFalse\tNNS\t[6]\n",
      ":\t1904\t:\tTrue\tFalse\t:\t[6]\n",
      "0.00969908\t1906\t0.00969908\tFalse\tFalse\tCD\t[6]\n",
      ",\t1917\t,\tTrue\tFalse\t,\t[6]\n",
      "source\t1919\tsource\tFalse\tFalse\tNN\t[6]\n",
      "port\t1926\tport\tFalse\tFalse\tNN\t[6]\n",
      "q1\t1931\tq1\tFalse\tFalse\tVBZ\t[6]\n",
      ":\t1934\t:\tTrue\tFalse\t:\t[6]\n",
      "0.63777565\t1936\t0.63777565\tFalse\tFalse\tCD\t[6]\n",
      ",\t1947\t,\tTrue\tFalse\t,\t[6]\n",
      "destination\t1949\tdestination\tFalse\tFalse\tNN\t[6]\n",
      "port\t1961\tport\tFalse\tFalse\tNN\t[6]\n",
      "q1\t1966\tq1\tFalse\tFalse\tVBZ\t[6]\n",
      ":\t1969\t:\tTrue\tFalse\t:\t[6]\n",
      "0.29315068\t1971\t0.29315068\tFalse\tFalse\tCD\t[6]\n",
      ",\t1982\t,\tTrue\tFalse\t,\t[6]\n",
      "internet\t1984\tinternet\tFalse\tFalse\tNN\t[6]\n",
      "protocol\t1993\tprotocol\tFalse\tFalse\tNN\t[6]\n",
      "length\t2002\tlength\tFalse\tFalse\tNN\t[6]\n",
      "q1\t2009\tq1\tFalse\tFalse\tNNS\t[6]\n",
      ":\t2012\t:\tTrue\tFalse\t:\t[6]\n",
      "0.18181818\t2014\t0.18181818\tFalse\tFalse\tCD\t[6]\n",
      ",\t2025\t,\tTrue\tFalse\t,\t[6]\n",
      "inter\t2027\tinter\tFalse\tFalse\tNN\t[6]\n",
      "arrival\t2033\tarrival\tFalse\tFalse\tNN\t[6]\n",
      "time\t2041\ttime\tFalse\tFalse\tNN\t[6]\n",
      "q1\t2046\tq1\tFalse\tFalse\tVBZ\t[6]\n",
      ":\t2049\t:\tTrue\tFalse\t:\t[6]\n",
      "0.00230832\t2051\t0.00230832\tFalse\tFalse\tCD\t[6]\n",
      ",\t2062\t,\tTrue\tFalse\t,\t[6]\n",
      "source\t2064\tsource\tFalse\tFalse\tNN\t[6]\n",
      "internet\t2071\tinternet\tFalse\tFalse\tNN\t[6]\n",
      "protocol\t2080\tprotocol\tFalse\tFalse\tNN\t[6]\n",
      "q2\t2089\tq2\tFalse\tFalse\tNN\t[6]\n",
      ":\t2092\t:\tTrue\tFalse\t:\t[6]\n",
      "0.0\t2094\t0.0\tFalse\tFalse\tCD\t[6]\n",
      ",\t2098\t,\tTrue\tFalse\t,\t[6]\n",
      "destination\t2100\tdestination\tFalse\tFalse\tNN\t[6]\n",
      "internet\t2112\tinternet\tFalse\tFalse\tNN\t[6]\n",
      "protocol\t2121\tprotocol\tFalse\tFalse\tNN\t[6]\n",
      "q2\t2130\tq2\tFalse\tFalse\tNN\t[6]\n",
      ":\t2133\t:\tTrue\tFalse\t:\t[6]\n",
      "0.0\t2135\t0.0\tFalse\tFalse\tCD\t[6]\n",
      ",\t2139\t,\tTrue\tFalse\t,\t[6]\n",
      "protocol\t2141\tprotocol\tFalse\tFalse\tNN\t[6]\n",
      "q2\t2150\tq2\tFalse\tFalse\tNN\t[6]\n",
      ":\t2153\t:\tTrue\tFalse\t:\t[6]\n",
      "0.0\t2155\t0.0\tFalse\tFalse\tCD\t[6]\n",
      ",\t2159\t,\tTrue\tFalse\t,\t[6]\n",
      "source\t2161\tsource\tFalse\tFalse\tNN\t[6]\n",
      "port\t2168\tport\tFalse\tFalse\tNN\t[6]\n",
      "q2\t2173\tq2\tFalse\tFalse\tNN\t[6]\n",
      ":\t2176\t:\tTrue\tFalse\t:\t[6]\n",
      "0.00079177\t2178\t0.00079177\tFalse\tFalse\tCD\t[6]\n",
      ",\t2189\t,\tTrue\tFalse\t,\t[6]\n",
      "destination\t2191\tdestination\tFalse\tFalse\tNN\t[6]\n",
      "port\t2203\tport\tFalse\tFalse\tNN\t[6]\n",
      "q2\t2208\tq2\tFalse\tFalse\tNNP\t[6]\n",
      ":\t2211\t:\tTrue\tFalse\t:\t[6]\n",
      "0.00266667\t2213\t0.00266667\tFalse\tFalse\tCD\t[6]\n",
      ",\t2224\t,\tTrue\tFalse\t,\t[6]\n",
      "internet\t2226\tinternet\tFalse\tFalse\tNN\t[6]\n",
      "protocol\t2235\tprotocol\tFalse\tFalse\tNN\t[6]\n",
      "length\t2244\tlength\tFalse\tFalse\tNN\t[6]\n",
      "q2\t2251\tq2\tFalse\tFalse\tNN\t[6]\n",
      ":\t2254\t:\tTrue\tFalse\t:\t[6]\n",
      "0.0\t2256\t0.0\tFalse\tFalse\tCD\t[6]\n",
      ",\t2260\t,\tTrue\tFalse\t,\t[6]\n",
      "inter\t2262\tinter\tFalse\tFalse\tNN\t[6]\n",
      "arrival\t2268\tarrival\tFalse\tFalse\tNN\t[6]\n",
      "time\t2276\ttime\tFalse\tFalse\tNN\t[6]\n",
      "q2\t2281\tq2\tFalse\tFalse\tNN\t[6]\n",
      ":\t2284\t:\tTrue\tFalse\t:\t[6]\n",
      "0.55797101\t2286\t0.55797101\tFalse\tFalse\tCD\t[6]\n",
      ",\t2297\t,\tTrue\tFalse\t,\t[6]\n",
      "source\t2299\tsource\tFalse\tFalse\tNN\t[6]\n",
      "internet\t2306\tinternet\tFalse\tFalse\tNN\t[6]\n",
      "protocol\t2315\tprotocol\tFalse\tFalse\tNN\t[6]\n",
      "q3\t2324\tq3\tFalse\tFalse\tNNP\t[6]\n",
      ":\t2327\t:\tTrue\tFalse\t:\t[6]\n",
      "0.0\t2329\t0.0\tFalse\tFalse\tCD\t[6]\n",
      ",\t2333\t,\tTrue\tFalse\t,\t[6]\n",
      "destination\t2335\tdestination\tFalse\tFalse\tNN\t[6]\n",
      "internet\t2347\tinternet\tFalse\tFalse\tNN\t[6]\n",
      "protocol\t2356\tprotocol\tFalse\tFalse\tNN\t[6]\n",
      "q3\t2365\tq3\tFalse\tFalse\tNNP\t[6]\n",
      ":\t2368\t:\tTrue\tFalse\t:\t[6]\n",
      "0.0\t2370\t0.0\tFalse\tFalse\tCD\t[6]\n",
      ",\t2374\t,\tTrue\tFalse\t,\t[6]\n",
      "protocol\t2376\tprotocol\tFalse\tFalse\tNN\t[6]\n",
      "q3\t2385\tq3\tFalse\tFalse\tNNP\t[6]\n",
      ":\t2388\t:\tTrue\tFalse\t:\t[6]\n",
      "0.0\t2390\t0.0\tFalse\tFalse\tCD\t[6]\n",
      ",\t2394\t,\tTrue\tFalse\t,\t[6]\n",
      "source\t2396\tsource\tFalse\tFalse\tNN\t[6]\n",
      "port\t2403\tport\tFalse\tFalse\tNN\t[6]\n",
      "q3\t2408\tq3\tFalse\tFalse\tNNP\t[6]\n",
      ":\t2411\t:\tTrue\tFalse\t:\t[6]\n",
      "0.19238715\t2413\t0.19238715\tFalse\tFalse\tCD\t[6]\n",
      ",\t2424\t,\tTrue\tFalse\t,\t[6]\n",
      "destination\t2426\tdestination\tFalse\tFalse\tNN\t[6]\n",
      "port\t2438\tport\tFalse\tFalse\tNN\t[6]\n",
      "q3\t2443\tq3\tFalse\tFalse\tNNP\t[6]\n",
      ":\t2446\t:\tTrue\tFalse\t:\t[6]\n",
      "0.00651859\t2448\t0.00651859\tFalse\tFalse\tCD\t[6]\n",
      ",\t2459\t,\tTrue\tFalse\t,\t[6]\n",
      "internet\t2461\tinternet\tFalse\tFalse\tNN\t[6]\n",
      "protocol\t2470\tprotocol\tFalse\tFalse\tNN\t[6]\n",
      "length\t2479\tlength\tFalse\tFalse\tNN\t[6]\n",
      "q3\t2486\tq3\tFalse\tFalse\tNNP\t[6]\n",
      ":\t2489\t:\tTrue\tFalse\t:\t[6]\n",
      "0.0\t2491\t0.0\tFalse\tFalse\tCD\t[6]\n",
      ",\t2495\t,\tTrue\tFalse\t,\t[6]\n",
      "inter\t2497\tinter\tFalse\tFalse\tNN\t[6]\n",
      "arrival\t2503\tarrival\tFalse\tFalse\tNN\t[6]\n",
      "time\t2511\ttime\tFalse\tFalse\tNN\t[6]\n",
      "q3\t2516\tq3\tFalse\tFalse\tNNP\t[6]\n",
      ":\t2519\t:\tTrue\tFalse\t:\t[6]\n",
      "0.5538544\t2521\t0.5538544\tFalse\tFalse\tCD\t[6]\n"
     ]
    }
   ],
   "source": [
    "#text = vocab_df['source internet protocol mean'][0]\n",
    "text = seq_df[0][0]\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(text)\n",
    "for token in doc : \n",
    "    print(\"{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t{5}\\t[6]\".format(\n",
    "    token.text, # 字元\n",
    "    token.idx, # 索引\n",
    "    token.lemma_,# 原型\n",
    "    token.is_punct,# 標點符號\n",
    "    token.is_space,# 空白\n",
    "    token.tag_ # 標記\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86660023 CARDINAL\n",
      "0.74068214 CARDINAL\n",
      "0.00992919 CARDINAL\n",
      "0.60208216 CARDINAL\n",
      "0.33323211 CARDINAL\n",
      "0.18181818 CARDINAL\n",
      "0.00222783 CARDINAL\n",
      "0.0 CARDINAL\n",
      "0.0 CARDINAL\n",
      "0.0 CARDINAL\n",
      "0.21686882 CARDINAL\n",
      "0.036159 CARDINAL\n",
      "0.0 CARDINAL\n",
      "0.00434957 CARDINAL\n",
      "0.4937372 CARDINAL\n",
      "0.53802464 CARDINAL\n",
      "0.18439253 CARDINAL\n",
      "0.27852452 CARDINAL\n",
      "0.4357907 CARDINAL\n",
      "0.64450623 CARDINAL\n",
      "0.15896699 CARDINAL\n",
      "0.0 CARDINAL\n",
      "0.0 CARDINAL\n",
      "0.0 CARDINAL\n",
      "0.05381951 CARDINAL\n",
      "0.01881635 CARDINAL\n",
      "0.0 CARDINAL\n",
      "0.0262479 CARDINAL\n",
      "0.86660023 CARDINAL\n",
      "0.81486863 CARDINAL\n",
      "0.0097555 CARDINAL\n",
      "0.48869568 CARDINAL\n",
      "0.31484203 CARDINAL\n",
      "0.18181818 CARDINAL\n",
      "1.915e-05 CARDINAL\n",
      "0.86660023 CARDINAL\n",
      "0.74068214 CARDINAL\n",
      "0.00972646 CARDINAL\n",
      "0.55976085 CARDINAL\n",
      "0.29315068 CARDINAL\n",
      "0.18181818 CARDINAL\n",
      "3.225e-05 CARDINAL\n",
      "0.86660021 CARDINAL\n",
      "0.67158376 CARDINAL\n",
      "0.00969908 CARDINAL\n",
      "0.63777565 CARDINAL\n",
      "0.29315068 CARDINAL\n",
      "0.18181818 CARDINAL\n",
      "0.00230832 CARDINAL\n",
      "0.0 CARDINAL\n",
      "0.0 CARDINAL\n",
      "0.0 CARDINAL\n",
      "0.00079177 CARDINAL\n",
      "0.00266667 CARDINAL\n",
      "0.0 CARDINAL\n",
      "0.55797101 CARDINAL\n",
      "0.0 CARDINAL\n",
      "0.0 CARDINAL\n",
      "0.0 CARDINAL\n",
      "0.19238715 CARDINAL\n",
      "0.00651859 CARDINAL\n",
      "0.0 CARDINAL\n",
      "0.5538544 CARDINAL\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents: # 實體詞彙\n",
    "    print(ent.text, ent.label_) # 實體詞彙, 實體詞彙類型, cardinal = numerals that do not fall under another type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">source internet protocol mean : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.86660023\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , destination internet protocol mean : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.74068214\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , protocol mean : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.00992919\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , source port mean : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.60208216\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , destination port mean : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.33323211\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , internet protocol length mean : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.18181818\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , inter arrival time mean : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.00222783\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , source internet protocol standard deviation : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.0\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , destination internet protocol standard deviation : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.0\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , protocol standard deviation : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.0\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , source port standard deviation : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.21686882\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , destination port standard deviation : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.036159\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , internet protocol length standard deviation : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.0\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , inter arrival time standard deviation : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.00434957\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , source internet protocol skewness : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.4937372\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , destination internet protocol skewness : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.53802464\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , protocol skewness : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.18439253\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , source port skewness : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.27852452\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , destination port skewness : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.4357907\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , internet protocol length skewness : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.64450623\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , inter arrival time skewness : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.15896699\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , source internet protocol kurtosis : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.0\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , destination internet protocol kurtosis : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.0\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , protocol kurtosis : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.0\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , source port kurtosis : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.05381951\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , destination port kurtosis : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.01881635\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , internet protocol length kurtosis : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.0\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , inter arrival time kurtosis : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.0262479\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , source internet protocol entropy : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.86660023\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , destination internet protocol entropy : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.81486863\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , protocol entropy : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.0097555\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , source port entropy : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.48869568\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , destination port entropy : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.31484203\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , internet protocol length entropy : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.18181818\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , inter arrival time entropy : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    1.915e-05\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , source internet protocol distinct : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.86660023\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , destination internet protocol distinct : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.74068214\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , protocol distinct : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.00972646\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , source port distinct : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.55976085\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , destination port distinct : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.29315068\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , internet protocol length distinct : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.18181818\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , inter arrival time distinct : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    3.225e-05\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , source internet protocol q1 : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.86660021\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , destination internet protocol q1 : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.67158376\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , protocol q1 : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.00969908\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , source port q1 : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.63777565\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , destination port q1 : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.29315068\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , internet protocol length q1 : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.18181818\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , inter arrival time q1 : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.00230832\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , source internet protocol q2 : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.0\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , destination internet protocol q2 : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.0\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , protocol q2 : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.0\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , source port q2 : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.00079177\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , destination port q2 : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.00266667\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , internet protocol length q2 : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.0\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , inter arrival time q2 : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.55797101\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , source internet protocol q3 : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.0\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , destination internet protocol q3 : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.0\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , protocol q3 : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.0\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , source port q3 : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.19238715\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , destination port q3 : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.00651859\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , internet protocol length q3 : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.0\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       " , inter arrival time q3 : \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    0.5538544\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc, style='ent', jupyter=True, \n",
    "                #options={'distance': 90}\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dns', 'dns', 'dns', ..., 'udp_ssdp', 'udp_ssdp', 'udp_ssdp'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atk_label = np.load('../SHAP/Network/traces/ml_data_example/label0.npy')\n",
    "#atk_label = np.char.add('DDoS : ', atk_label)\n",
    "atk_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dns'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atk_label_df = pd.DataFrame(atk_label)\n",
    "atk_label_df[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dns\t0\tdns\tFalse\tFalse\tNN\t[6]\n"
     ]
    }
   ],
   "source": [
    "text = atk_label_df[0][0]\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(text)\n",
    "\n",
    "for token in doc : \n",
    "    print(\"{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t{5}\\t[6]\".format(\n",
    "    token.text, # 字元\n",
    "    token.idx, # 索引\n",
    "    token.lemma_,# 原型\n",
    "    token.is_punct,# 標點符號\n",
    "    token.is_space,# 空白\n",
    "    token.tag_ # 標記\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    dns\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='ent', jupyter=True, \n",
    "                #options={'distance': 90}\n",
    "                )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Def & import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import exists\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import log_softmax, pad\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import torchtext.datasets as datasets\n",
    "import spacy\n",
    "import GPUtil\n",
    "import warnings\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "import portalocker\n",
    "import torchdata\n",
    "import torchtext\n",
    "from torch.utils.data import Dataset\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "RUN_EXAMPLES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_interactive_notebook():\n",
    "    return __name__ == \"__main__\"\n",
    "\n",
    "\n",
    "def show_example(fn, args=[]):\n",
    "    if __name__ == \"__main__\" and RUN_EXAMPLES:\n",
    "        return fn(*args)\n",
    "\n",
    "\n",
    "def execute_example(fn, args=[]):\n",
    "    if __name__ == \"__main__\" and RUN_EXAMPLES:\n",
    "        fn(*args)\n",
    "\n",
    "\n",
    "class DummyOptimizer(torch.optim.Optimizer):\n",
    "    def __init__(self):\n",
    "        self.param_groups = [{\"lr\": 0}]\n",
    "        None\n",
    "\n",
    "    def step(self):\n",
    "        None\n",
    "\n",
    "    def zero_grad(self, set_to_none=False):\n",
    "        None\n",
    "\n",
    "\n",
    "class DummyScheduler:\n",
    "    def step(self):\n",
    "        None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EncoderDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A standard Encoder-Decoder architecture. Base for this and many\n",
    "    other models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "\n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        \"Take in and process masked src and target sequences.\"\n",
    "        return self.decode(self.encode(src, src_mask), src_mask, tgt, tgt_mask)\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        return self.encoder(self.src_embed(src), src_mask)\n",
    "\n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"Define standard linear + softmax generation step.\"\n",
    "\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return log_softmax(self.proj(x), dim=-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module (See citation for details).\"\n",
    "\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"Core encoder is a stack of N layers\"\n",
    "\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"Pass the input (and mask) through each layer in turn.\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)\n",
    "    # rahter than\n",
    "    # return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n",
    "    # rahter than\n",
    "    # return self.norm(x + self.dropout(sublayer(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \"Encoder is made up of self-attn and feed forward (defined below)\"\n",
    "\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"Follow Figure 1 (left) for connections.\"\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        return self.sublayer[1](x, self.feed_forward)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"Generic N layer decoder with masking.\"\n",
    "\n",
    "    def __init__(self, layer, N):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "\n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \"Decoder is made of self-attn, src-attn, and feed forward (defined below)\"\n",
    "\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn  # cross attention\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
    "\n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        \"Follow Figure 1 (right) for connections.\"\n",
    "        m = memory\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
    "        return self.sublayer[2](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = torch.triu(torch.ones(attn_shape), diagonal=1).type(\n",
    "        torch.uint8\n",
    "    )\n",
    "    return subsequent_mask == 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = scores.softmax(dim=-1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"Implements Figure 2\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "\n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k\n",
    "        query, key, value = [\n",
    "            lin(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "            for lin, x in zip(self.linears, (query, key, value))\n",
    "        ]\n",
    "\n",
    "        # 2) Apply attention on all the projected vectors in batch.\n",
    "        x, self.attn = attention(\n",
    "            query, key, value, mask=mask, dropout=self.dropout\n",
    "        )\n",
    "\n",
    "        # 3) \"Concat\" using a view and apply a final linear.\n",
    "        x = (\n",
    "            x.transpose(1, 2)\n",
    "            .contiguous()\n",
    "            .view(nbatches, -1, self.h * self.d_k)\n",
    "        )\n",
    "        del query\n",
    "        del key\n",
    "        del value\n",
    "        return self.linears[-1](x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(self.w_1(x).relu()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding and sofx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lut(x) * math.sqrt(self.d_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PositionalEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)\n",
    "            # torch.pow(10000, torch.arange(0., d_model, 2) / d_model)  -> compute 2 time slower than above\n",
    "        )\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, : x.size(1)].requires_grad_(False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(\n",
    "    src_vocab, tgt_vocab, N=6, d_model=512, d_ff=2048, h=8, dropout=0.1\n",
    "):\n",
    "    \"Helper: Construct a model from hyperparameters.\"\n",
    "    # duplicate a new model\n",
    "    c = copy.deepcopy\n",
    "    # multi-heead attention\n",
    "    attn = MultiHeadedAttention(h, d_model)\n",
    "    # FFN\n",
    "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "    # PE \n",
    "    position = PositionalEncoding(d_model, dropout)\n",
    "    # Build model\n",
    "    model = EncoderDecoder(\n",
    "        # Encoder \n",
    "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
    "        # Decoder\n",
    "        Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout), N),\n",
    "        # Inputs' embedding and PE\n",
    "        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n",
    "        # Outputs' embedding and PE\n",
    "        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n",
    "        # Linear layer and softmax in Decoder, to predict the next token\n",
    "        Generator(d_model, tgt_vocab),\n",
    "    )\n",
    "\n",
    "    # This was important from their code.\n",
    "    # Initialize parameters with Glorot / fan_avg.\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch and masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    \"\"\"Object for holding a batch of data with mask during training.\"\"\"\n",
    "    # Define a 'Batch' to store one 'batch' 's src, tgt, src_mask, etc.\n",
    "    def __init__(self, src, tgt=None, pad=2):  # 2 = <blank>\n",
    "        '''\n",
    "        src : consistency as in EncoderDecoder#forward.\n",
    "            Yet run word embedding sentence, like  [[ 0, 5, 4, 6, 1, 2, 2]]\n",
    "            shape is (1,7), which batch size = 1, sentence size = 7.\n",
    "            0 : bos, begin of sentence\n",
    "            1 : eos, end of sentence\n",
    "            2 : pad, space\n",
    "        tgt : similiar to src\n",
    "        '''\n",
    "        self.src = src\n",
    "        '''\n",
    "        build src_mask : cover the sentence in src's pad, since those aren't belong to sentence, shouldn't engaging computation\n",
    "                         like                   [[ 0,    5,    4,    6,    1,     2,    2]], \n",
    "                         src_mask will be : [[[ True, True, True, True, True, False, False ]]]\n",
    "                         bos, eos regard as part of sentence \n",
    "                         \n",
    "                         unsqueeze since will process mask in Attention'score, in order to make shape consistency between scores and mask\n",
    "        '''\n",
    "        self.src_mask = (src != pad).unsqueeze(-2)\n",
    "        if tgt is not None:\n",
    "            '''\n",
    "            Each sentence remove the last word.\n",
    "            like tgt' shape (16,30), \n",
    "                batch size = 16, each sentence contain 30 words\n",
    "            After this will be (16,29)\n",
    "            The reason why doing this : tgt store -> decoder's input. and decoder's input is impossible contain the last word\n",
    "            In case we predict \" <bos> I love you  <eos>\"\n",
    "                1. <bos> \n",
    "                2. <bos> I \n",
    "                3. <bos> I love\n",
    "                4. <bos> I love you\n",
    "            will not appear '<eos>', so has to remove the last word\n",
    "            '''\n",
    "            self.tgt = tgt[:, :-1]\n",
    "            '''\n",
    "            same reason above, we don't want to contain <bos>\n",
    "            '''\n",
    "            self.tgt_y = tgt[:, 1:]\n",
    "            \n",
    "            '''\n",
    "            Build tgt_mask : Slightly different with src_mask, except for covering pad part, also need cover the top right of the diagonal line as well\n",
    "                [[ 0, 5, 4, 6, 1, 2, 2]]\n",
    "            tgt_mask will be : \n",
    "            [[[ True, False, False, False, False, False, False],\n",
    "              [ True,  True, False, False, False, False, False],\n",
    "              [ True,  True,  True, False, False, False, False],\n",
    "              [ True,  True,  True,  True, False, False, False],\n",
    "              [ True,  True,  True,  True,  True, False, False],\n",
    "              [ True,  True,  True,  True,  True, False, False],\n",
    "              [ True,  True,  True,  True,  True, False, False]]]\n",
    "\n",
    "            '''\n",
    "            self.tgt_mask = self.make_std_mask(self.tgt, pad)\n",
    "            \n",
    "            '''\n",
    "            The total number of tokens of tgt_y for this Batch. The value is a number, e.g. tensor(266) means tgt_y has 266 meaningful tokens\n",
    "            which is the number of words that go out to the <pad> section. \n",
    "            This is saved for use in the loss regularization\n",
    "            Note that here is tgt_y, and tgt_y removes the \"<bos>\", so the token count does not contain \"<bos>\".\n",
    "\n",
    "            '''\n",
    "            self.ntokens = (self.tgt_y != pad).data.sum()\n",
    "\n",
    "    @staticmethod\n",
    "    def make_std_mask(tgt, pad):\n",
    "        \"Create a mask to hide padding and future words. (tgt_mask)\"\n",
    "        tgt_mask = (tgt != pad).unsqueeze(-2)\n",
    "        \n",
    "        '''\n",
    "        Subsequent_mask is used to get the stepped Mask. then \"&\" operation with tgt_mask\n",
    "         E.g. tgt_mask : [[[ True, True, False ]]]\n",
    "         subsequent_mask' result ：\n",
    "                        [[[ True, False, False ],\n",
    "                          [ True, True, False ],\n",
    "                          [ True, True, True ]]]\n",
    "        Then tgt_mask & subsequent_mask result ：\n",
    "                        [[[ True, False, False ],\n",
    "                          [ True, True, False ],\n",
    "                          [ True, True, False ]]]\n",
    "        '''\n",
    "        tgt_mask = tgt_mask & subsequent_mask(tgt.size(-1)).type_as(\n",
    "            tgt_mask.data\n",
    "        )\n",
    "        return tgt_mask"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainState:\n",
    "    \"\"\"Track number of steps, examples, and tokens processed\"\"\"\n",
    "    '''\n",
    "    step times, each batch count once\n",
    "    '''\n",
    "    step: int = 0  # Steps in the current epoch\n",
    "    # parameter update times, optimzer.step()\n",
    "    accum_step: int = 0  # Number of gradient accumulation steps\n",
    "    samples: int = 0  # total # of examples used\n",
    "    tokens: int = 0  # total # of tokens processed (target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(\n",
    "    data_iter,\n",
    "    model,\n",
    "    loss_compute,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    mode=\"train\",\n",
    "    accum_iter=1,\n",
    "    train_state=TrainState(),\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a single epoch\n",
    "    data_iter : iterable object that returns one Batch object at a time\n",
    "    scheduler: LambdaLR object to adjust Adam's learning rate and implement WarmUp\n",
    "    accum_iter: how many batches to update the parameters once, default is 1, that is, each batch to update the parameters\n",
    "    train_state: TrainState object, used to save some training state\n",
    "    \"\"\"\n",
    "    \n",
    "    start = time.time()\n",
    "    # Record the total number of tokens of the target, and clear 0 after each log print\n",
    "    total_tokens = 0\n",
    "    \n",
    "    total_loss = 0\n",
    "    tokens = 0\n",
    "    n_accum = 0 # How many times the model parameters have been updated in this epoch\n",
    "    for i, batch in enumerate(data_iter):\n",
    "        '''\n",
    "        Forward pass. Equivalent to model(batch.src, batch.tgt, batch.src_mask, batch.tgt_mask)\n",
    "        But note that the out here is the output of the Decoder, not the Generator, because in EncoderDecoder\n",
    "        The generator is not used in the forward. generator is called in loss_compute\n",
    "        '''\n",
    "        out = model.forward(\n",
    "            batch.src, batch.tgt, batch.src_mask, batch.tgt_mask\n",
    "        )\n",
    "        \n",
    "        \"\"\"\n",
    "        Computational loss, the three parameters passed in are:\n",
    "        1. out: the output of EncoderDecoder, the value does not pass the final linear layer, the over linear layer is integrated in the computational loss\n",
    "        2. tgt_y: all tokens to be predicted, for example, if src is `<bos> I love you <eos>`, then `tgt_y` is\n",
    "                  `I love you <eos>`\n",
    "        3. ntokens: the number of valid tokens in this batch of batches. Used to regularize the los.\n",
    "\n",
    "        Returns two losses, where loss_node is after regularization, so this is used for gradient descent.\n",
    "                    And the loss is unregularized, used to count total_loss.\n",
    "        \"\"\"\n",
    "        loss, loss_node = loss_compute(out, batch.tgt_y, batch.ntokens)\n",
    "        # loss_node = loss_node / accum_iter\n",
    "        if mode == \"train\" or mode == \"train+log\":\n",
    "            # Calculate gradients\n",
    "            loss_node.backward()\n",
    "            # Record the number of steps\n",
    "            train_state.step += 1\n",
    "            # Record the number of samples. batch.src.shape[0] gets the Batch size\n",
    "            train_state.samples += batch.src.shape[0]\n",
    "            # Record the number of processed tokens\n",
    "            train_state.tokens += batch.ntokens\n",
    "            \n",
    "            # If the accum_iter is reached, a parameter update is used\n",
    "            if i % accum_iter == 0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                # Record the number of parameter updates for this epoch\n",
    "                n_accum += 1\n",
    "                # Record the number of parameter updates of the model\n",
    "                train_state.accum_step += 1\n",
    "            # Update learning rate\n",
    "            scheduler.step()\n",
    "\n",
    "        total_loss += loss\n",
    "        # Cumulative processed tokens\n",
    "        total_tokens += batch.ntokens\n",
    "        # Accumulate the tokens processed since the last print log\n",
    "        tokens += batch.ntokens\n",
    "        # Logs are printed every 40 batches.\n",
    "        if i % 40 == 1 and (mode == \"train\" or mode == \"train+log\"):\n",
    "            # Print out the current learning rate\n",
    "            lr = optimizer.param_groups[0][\"lr\"]\n",
    "            # Record the consumption time of these 40 batches\n",
    "            elapsed = time.time() - start\n",
    "            print(\n",
    "                (\n",
    "                    \"Epoch Step: %6d | Accumulation Step: %3d | Loss: %6.2f \"\n",
    "                    + \"| Tokens / Sec: %7.1f | Learning Rate: %6.1e\"\n",
    "                )\n",
    "                # i: the number of batches in this epoch\n",
    "                # n_accum: how many times the model parameters \n",
    "                # tokens / elapsed: the number of tokens that can be processed per second\n",
    "                % (i, n_accum, loss / batch.ntokens, tokens / elapsed, lr)\n",
    "            )\n",
    "            start = time.time()\n",
    "            tokens = 0\n",
    "        del loss\n",
    "        del loss_node\n",
    "    return total_loss / total_tokens, train_state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate(step, model_size, factor, warmup):\n",
    "    \"\"\"\n",
    "    we have to default the step to 1 for LambdaLR function\n",
    "    to avoid zero raising to negative power.\n",
    "    \"\"\"\n",
    "    if step == 0:\n",
    "        step = 1\n",
    "    return factor * (\n",
    "        model_size ** (-0.5) * min(step ** (-0.5), step * warmup ** (-1.5))\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothing(nn.Module):\n",
    "    \"Implement label smoothing.\"\n",
    "\n",
    "    def __init__(self, size, padding_idx, smoothing=0.0):\n",
    "        '''\n",
    "        size : dst dictionary size\n",
    "        padding_index : space <blank> correspond in dictionary's index, <blank> equalize <pad>\n",
    "        smothing : Smoothing factor, 0 means no smoothing\n",
    "        '''\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.criterion = nn.KLDivLoss(reduction=\"sum\")\n",
    "        self.padding_idx = padding_idx\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.size = size\n",
    "        self.true_dist = None\n",
    "\n",
    "    def forward(self, x, target):\n",
    "        '''\n",
    "        X : generator' output ratio distribution. shape = (batch_size, dictionary size)\n",
    "        target : dst label. shape = (batch_size)\n",
    "        '''\n",
    "        # Ensure generator's output dimension same as dictionary size, otherwise will occur error when compute loss \n",
    "        assert x.size(1) == self.size\n",
    "        # To create same tensor' shape as x\n",
    "        # Hypothesis x' shape (2, 6), which means batch_size = 2 , dictionary size = 6\n",
    "        true_dist = x.data.clone()\n",
    "        '''\n",
    "        Fill all true_dist to self.smoothing/(self.size - 2).\n",
    "        Hypothesis smoothing = 0.2, then padding all 0.2 / 4 = 0.05\n",
    "        Now true_dist will be ：\n",
    "        [[0.05, 0.05, 0.05, 0.05, 0.05, 0.05],\n",
    "         [0.05, 0.05, 0.05, 0.05, 0.05, 0.05]]\n",
    "        '''\n",
    "        true_dist.fill_(self.smoothing / (self.size - 2))\n",
    "        '''\n",
    "        Hypothesis in this example target.data.unsqueeze(1) is [[2], [3]], i.e. the labels of the 2 data are 2 and 3 respectively\n",
    "        Then true_dist becomes after scatter.\n",
    "        [[0.05, 0.05, 0.8, 0.05, 0.05, 0.05].\n",
    "         [0.05, 0.05, 0.05, 0.8, 0.05, 0.05]]\n",
    "        '''\n",
    "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        true_dist[:, self.padding_idx] = 0\n",
    "        mask = torch.nonzero(target.data == self.padding_idx)\n",
    "        if mask.dim() > 0:\n",
    "            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
    "        self.true_dist = true_dist\n",
    "        '''\n",
    "        since smoothing' loss mask <blank>(spacy),\n",
    "        in this part will not engag in loss computation\n",
    "        '''\n",
    "        return self.criterion(x, true_dist.clone().detach())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loss compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLossCompute:\n",
    "    \"A simple loss compute and train function.\"\n",
    "\n",
    "    def __init__(self, generator, criterion):\n",
    "        '''\n",
    "        generator : class Generator, predict the next token via decoder's output\n",
    "        criterion : class LabelSmoothing, process smooth and loss computation with Label\n",
    "        '''\n",
    "        self.generator = generator\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def __call__(self, x, y, norm):\n",
    "        '''\n",
    "        x : EncoderDecoder's output which is decoder's output\n",
    "        y : batch.tgt_y, all tokens that are predicted,\n",
    "            e.g. src is   : ' <bos> I love you <eos>'\n",
    "                 tgt_y is : ' 我 愛 你 <eos>'\n",
    "        norm : batch.tokens, The number of valid tokens in tgt_y. Used to regularize the loss\n",
    "        '''\n",
    "        x = self.generator(x)\n",
    "        # Use KLDivLoss rpocess loss computation , then divided loss by batch.ntokens to regularization\n",
    "        sloss = (\n",
    "            self.criterion(\n",
    "                x.contiguous().view(-1, x.size(-1)), y.contiguous().view(-1)\n",
    "            )\n",
    "            / norm\n",
    "        )\n",
    "        return sloss.data * norm, sloss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class textDataset(Dataset):\n",
    "    def __init__(self, csv_path = './ml_example_dataset/vocab.csv'):\n",
    "        super().__init__()\n",
    "        self.install_data = pd.read_csv(csv_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.install_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        input_data = pd.DataFrame([])\n",
    "        label = pd.DataFrame([])\n",
    "        input_data = self.install_data.iloc[idx,0]\n",
    "        label = self.install_data.iloc[idx,1]\n",
    "        return input_data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "showresult = textDataset('./ml_example_dataset/vocab.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' def tokenize(text, tokenizer):\\n    return [tok.text for tok in tokenizer.tokenizer(text)]\\ndef yield_tokens(data_iter=showresult, tokenizer, index)\\n    for from_to_tuple in data_iter:\\n        yield tokenizer.tokenize(from_to_tuple[index]) '"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" def tokenize(text, tokenizer):\n",
    "    return [tok.text for tok in tokenizer.tokenizer(text)]\n",
    "def yield_tokens(data_iter=showresult, tokenizer, index)\n",
    "    for from_to_tuple in data_iter:\n",
    "        yield tokenizer.tokenize(from_to_tuple[index]) \"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tokenizers():\n",
    "    try:\n",
    "        spacy_en_stat = spacy.load('en_core_web_sm')\n",
    "    except IOError:\n",
    "        os.system('python -m spacy download en_core_web_sm')\n",
    "        spacy_en_stat = spacy.load('en_core_web_sm')\n",
    "    try:\n",
    "        spacy_en_atk = spacy.load('en_core_web_sm')\n",
    "    except IOError:\n",
    "        os.system('python -m spacy download en_core_web_sm')\n",
    "        spacy_en_atk = spacy.load('en_core_web_sm')\n",
    "    return spacy_en_stat, spacy_en_atk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, tokenizer):\n",
    "    return [tok.text for tok in tokenizer.tokenizer(text)]\n",
    "def yield_tokens(data_iter, tokenizer, index):\n",
    "    for from_to_tuple in data_iter:\n",
    "        yield tokenizer(from_to_tuple[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buliding statistics input vocabulary...\n",
      "Buliding DDoS attack  vocabulary...\n",
      "Finished. \n",
      "Vocabulary sizes:\n",
      "Vocabulary size: 514214\n",
      "Vocabulary size: 13\n"
     ]
    }
   ],
   "source": [
    "def build_vocabulary(spacy_en_stat, spacy_en_atk):\n",
    "    def tokenize_en_stat(text):\n",
    "        return tokenize(text, spacy_en_stat)\n",
    "    def tokenize_en_atk(text):\n",
    "        return tokenize(text, spacy_en_atk)\n",
    "    print(\"Buliding statistics input vocabulary...\")\n",
    "    #train, val, test = np.array(seq_df[0][0:5607]) , np.array(seq_df[0][5608 : 11215]), np.array(seq_df[0][11215: 16822])\n",
    "    train, val, test = showresult[0:5607] , showresult[5608 : 11215], showresult[11215: 16822] \n",
    "    vocab_src = build_vocab_from_iterator(\n",
    "        #yield_tokens(train +  val +  test,tokenize_en_stat, index=0),\n",
    "        yield_tokens(showresult, tokenize_en_stat, 0),\n",
    "        min_freq = 1,\n",
    "        specials=[\"<:>\",\"<,>\", \"<blank>\", \"<unk>\"],\n",
    "    )\n",
    "\n",
    "    print(\"Buliding DDoS attack  vocabulary...\")\n",
    "    #train, val, test = np.array(atk_label_df[0][0:5607]) , np.array(atk_label_df[0][5608 : 11215]), np.array(atk_label_df[0][11215: 16822])\n",
    "    train, val, test = showresult[0:5607] , showresult[5608 : 11215], showresult[11215: 16822]\n",
    "    vocab_tgt = build_vocab_from_iterator(\n",
    "        #yield_tokens(train +  val +  test, tokenize_en_atk, index=1),\n",
    "        yield_tokens(showresult, tokenize_en_atk, 1),\n",
    "        min_freq = 1,\n",
    "        specials=[\"<:>\",\"<,>\", \"<blank>\", \"<unk>\"],\n",
    "    )\n",
    "    vocab_src.set_default_index(vocab_src[\"<unk>\"])\n",
    "    vocab_tgt.set_default_index(vocab_tgt[\"<unk>\"])\n",
    "    return vocab_src, vocab_tgt\n",
    "def load_vocab(spacy_en_stat, spacy_en_atk):\n",
    "    if not exists('vocab.pt'):\n",
    "        vocab_src, vocab_tgt = build_vocabulary(spacy_en_stat,spacy_en_atk)\n",
    "        torch.save((vocab_src,vocab_tgt) ,'vocab.pt')\n",
    "    else:\n",
    "        vocab_src, vocab_tgt = torch.load('vocab.pt')\n",
    "    print(\"Finished. \\nVocabulary sizes:\")\n",
    "    print(\"Vocabulary size: %d\" % len(vocab_src))\n",
    "    print(\"Vocabulary size: %d\" % len(vocab_tgt))\n",
    "    return vocab_src, vocab_tgt\n",
    "if is_interactive_notebook():\n",
    "    # global variables used later in the script\n",
    "    spacy_en_stat, spacy_en_atk = show_example(load_tokenizers)\n",
    "    vocab_src, vocab_tgt = show_example(load_vocab, args=[spacy_en_stat, spacy_en_atk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 19, 53887, 10, 7)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check my dictionary\n",
    "vocab_src['0.86660023'], vocab_src['mean'],vocab_src['0.8670171'], vocab_tgt['dns'], vocab_tgt['syn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 7)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_src['sources'], vocab_src['internet']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(\n",
    "    batch,\n",
    "    src_pipeline, # text_pipeline \n",
    "    tgt_pipeline, # label_pipeline\n",
    "    src_vocab,\n",
    "    tgt_vocab,\n",
    "    device,\n",
    "    max_padding=128,\n",
    "    pad_id=2,\n",
    "):\n",
    "    bs_id = torch.tensor([0], device=device)  # <s> token id\n",
    "    eos_id = torch.tensor([1], device=device)  # </s> token id\n",
    "    src_list, tgt_list = [], []\n",
    "    for (_src, _tgt) in batch:\n",
    "        processed_src = torch.cat(\n",
    "            [\n",
    "                bs_id,\n",
    "                torch.tensor(\n",
    "                    src_vocab(src_pipeline(_src)),\n",
    "                    dtype=torch.int64,\n",
    "                    device=device,\n",
    "                ),\n",
    "                eos_id,\n",
    "            ],\n",
    "            0,\n",
    "        )\n",
    "        processed_tgt = torch.cat(\n",
    "            [\n",
    "                bs_id,\n",
    "                torch.tensor(\n",
    "                    tgt_vocab(tgt_pipeline(_tgt)),\n",
    "                    dtype=torch.int64,\n",
    "                    device=device,\n",
    "                ),\n",
    "                eos_id,\n",
    "            ],\n",
    "            0,\n",
    "        )\n",
    "        src_list.append(\n",
    "            # warning - overwrites values for negative values of padding - len\n",
    "            pad(\n",
    "                processed_src,\n",
    "                (\n",
    "                    0,\n",
    "                    max_padding - len(processed_src),\n",
    "                ),\n",
    "                value=pad_id,\n",
    "            )\n",
    "        )\n",
    "        tgt_list.append(\n",
    "            pad(\n",
    "                processed_tgt,\n",
    "                (0, max_padding - len(processed_tgt)),\n",
    "                value=pad_id,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    src = torch.stack(src_list)\n",
    "    tgt = torch.stack(tgt_list)\n",
    "    return (src, tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(\n",
    "    device,\n",
    "    vocab_src,\n",
    "    vocab_tgt,\n",
    "    spacy_en_stat,\n",
    "    spacy_en_atk,\n",
    "    batch_size=12000,\n",
    "    max_padding=128,\n",
    "    is_distributed=True,\n",
    "):\n",
    "    # def create_dataloaders(batch_size=12000):\n",
    "    \"\"\" def tokenize_de(text):\n",
    "        return tokenize(text, spacy_de)\n",
    "\n",
    "    def tokenize_en(text):\n",
    "        return tokenize(text, spacy_en) \"\"\"\n",
    "    def tokenize_en_stat(text):\n",
    "        return tokenize(text, spacy_en_stat)\n",
    "    def tokenize_en_atk(text):\n",
    "        return tokenize(text, spacy_en_atk)\n",
    "    \n",
    "    def collate_fn(batch):\n",
    "        return collate_batch(\n",
    "            batch,\n",
    "            tokenize_en_stat,\n",
    "            tokenize_en_atk,\n",
    "            vocab_src,\n",
    "            vocab_tgt,\n",
    "            device,\n",
    "            max_padding=max_padding,\n",
    "            pad_id=vocab_src.get_stoi()[\"<blank>\"],\n",
    "        )\n",
    "\n",
    "    #train_iter, valid_iter, test_iter = np.array(seq_df[0][0:5607]) , np.array(seq_df[0][5608 : 11215]), np.array(seq_df[0][11215: 16822])\n",
    "    train_iter, valid_iter, test_iter = showresult[0:5607] , showresult[5608 : 11215], showresult[11215: 16822]\n",
    "    train_iter_map = to_map_style_dataset(train_iter) \n",
    "    valid_iter_map = to_map_style_dataset(valid_iter)\n",
    "    train_dataloader = DataLoader(\n",
    "        train_iter_map,\n",
    "        batch_size=batch_size,\n",
    "        #shuffle = (train_sampler is None),\n",
    "        shuffle=True,\n",
    "        #sampler=train_sampler,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    valid_dataloader = DataLoader(\n",
    "        valid_iter_map,\n",
    "        batch_size=batch_size,\n",
    "        #shuffle=(valid_sampler is None),\n",
    "        shuffle = True,\n",
    "        #sampler=valid_sampler,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    return train_dataloader, valid_dataloader"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_worker(\n",
    "    gpu,\n",
    "    ngpus_per_node,\n",
    "    vocab_src,\n",
    "    vocab_tgt,\n",
    "    spacy_en_stat,\n",
    "    spacy_en_atk,\n",
    "    config,\n",
    "    is_distributed=False,\n",
    "):\n",
    "    print(f\"Train worker process using GPU: {gpu} for training\", flush=True)\n",
    "    torch.cuda.set_device(gpu)\n",
    "\n",
    "    pad_idx = vocab_tgt[\"<blank>\"]\n",
    "    d_model = 512\n",
    "    model = make_model(len(vocab_src), len(vocab_tgt), N=6)\n",
    "    model.cuda(gpu)\n",
    "    module = model\n",
    "    is_main_process = True\n",
    "    if is_distributed:\n",
    "        dist.init_process_group(\n",
    "            \"nccl\", init_method=\"env://\", rank=gpu, world_size=ngpus_per_node\n",
    "        )\n",
    "        model = DDP(model, device_ids=[gpu])\n",
    "        module = model.module\n",
    "        is_main_process = gpu == 0\n",
    "\n",
    "    criterion = LabelSmoothing(\n",
    "        size=len(vocab_tgt), padding_idx=pad_idx, smoothing=0.1\n",
    "    )\n",
    "    criterion.cuda(gpu)\n",
    "\n",
    "    train_dataloader, valid_dataloader = create_dataloaders(\n",
    "        gpu,\n",
    "        vocab_src,\n",
    "        vocab_tgt,\n",
    "        spacy_en_stat,\n",
    "        spacy_en_atk,\n",
    "        batch_size=config[\"batch_size\"] // ngpus_per_node,\n",
    "        max_padding=config[\"max_padding\"],\n",
    "        is_distributed=is_distributed,\n",
    "    )\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=config[\"base_lr\"], betas=(0.9, 0.98), eps=1e-9\n",
    "    )\n",
    "    lr_scheduler = LambdaLR(\n",
    "        optimizer=optimizer,\n",
    "        lr_lambda=lambda step: rate(\n",
    "            step, d_model, factor=1, warmup=config[\"warmup\"]\n",
    "        ),\n",
    "    )\n",
    "    train_state = TrainState()\n",
    "\n",
    "    for epoch in range(config[\"num_epochs\"]):\n",
    "        if is_distributed:\n",
    "            train_dataloader.sampler.set_epoch(epoch)\n",
    "            valid_dataloader.sampler.set_epoch(epoch)\n",
    "\n",
    "        model.train()\n",
    "        print(f\"[GPU{gpu}] Epoch {epoch} Training ====\", flush=True)\n",
    "        _, train_state = run_epoch(\n",
    "            (Batch(b[0], b[1], pad_idx) for b in train_dataloader),\n",
    "            model,\n",
    "            SimpleLossCompute(module.generator, criterion),\n",
    "            optimizer,\n",
    "            lr_scheduler,\n",
    "            mode=\"train+log\",\n",
    "            accum_iter=config[\"accum_iter\"],\n",
    "            train_state=train_state,\n",
    "        )\n",
    "\n",
    "        GPUtil.showUtilization()\n",
    "        if is_main_process:\n",
    "            file_path = \"%s%.2d.pt\" % (config[\"file_prefix\"], epoch)\n",
    "            torch.save(module.state_dict(), file_path)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        print(f\"[GPU{gpu}] Epoch {epoch} Validation ====\", flush=True)\n",
    "        model.eval()\n",
    "        sloss = run_epoch(\n",
    "            (Batch(b[0], b[1], pad_idx) for b in valid_dataloader),\n",
    "            model,\n",
    "            SimpleLossCompute(module.generator, criterion),\n",
    "            DummyOptimizer(),\n",
    "            DummyScheduler(),\n",
    "            mode=\"eval\",\n",
    "        )\n",
    "        print(sloss)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    if is_main_process:\n",
    "        file_path = \"%sfinal.pt\" % config[\"file_prefix\"]\n",
    "        torch.save(module.state_dict(), file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_distributed_model(vocab_src, vocab_tgt, spacy_en_stat, spacy_en_atk, config):\n",
    "    #from the_annotated_transformer import train_worker\n",
    "\n",
    "    ngpus = torch.cuda.device_count()\n",
    "    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "    os.environ[\"MASTER_PORT\"] = \"12356\"\n",
    "    print(f\"Number of GPUs detected: {ngpus}\")\n",
    "    print(\"Spawning training processes ...\")\n",
    "    mp.spawn(\n",
    "        train_worker,\n",
    "        nprocs=ngpus,\n",
    "        args=(ngpus, vocab_src, vocab_tgt, spacy_en_stat, spacy_en_atk, config, True),\n",
    "    )\n",
    "\n",
    "\n",
    "def train_model(vocab_src, vocab_tgt, spacy_en_stat, spacy_en_atk, config):\n",
    "    if config[\"distributed\"]:\n",
    "        train_distributed_model(\n",
    "            vocab_src, vocab_tgt, spacy_en_stat, spacy_en_atk, config\n",
    "        )\n",
    "    else:\n",
    "        train_worker(\n",
    "            0, 1, vocab_src, vocab_tgt, spacy_en_stat, spacy_en_atk, config, False\n",
    "        )\n",
    "\n",
    "\n",
    "def load_trained_model():\n",
    "    config = {\n",
    "        \"batch_size\": 32,\n",
    "        \"distributed\": False,\n",
    "        \"num_epochs\": 8,\n",
    "        \"accum_iter\": 10,\n",
    "        \"base_lr\": 1.0,\n",
    "        \"max_padding\": 72,\n",
    "        \"warmup\": 3000,\n",
    "        \"file_prefix\": \"ml_example_model_\",\n",
    "    }\n",
    "    model_path = \"ml_example_model_final.pt\"\n",
    "    if not exists(model_path):\n",
    "        train_model(vocab_src, vocab_tgt, spacy_en_stat, spacy_en_atk, config)\n",
    "\n",
    "    model = make_model(len(vocab_src), len(vocab_tgt), N=6)\n",
    "    model.load_state_dict(torch.load(\"ml_example_model_final.pt\"))\n",
    "    return model\n",
    "\n",
    "\n",
    "if is_interactive_notebook():\n",
    "    model = load_trained_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
